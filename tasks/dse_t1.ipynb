{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TASK 1: RESTAURANT TIPS**\n",
    "**Pranay Srivastava\\\n",
    "ME379M: Data Science for Engineers\\\n",
    "DUE: 01/17/2023**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "* Perform linear regression on relevant categories (serving as filters) of a training subset of data using testing examples from the dataset\n",
    "    * Will work with the dataset as a Pandas dataframe\n",
    "    * 80/20 train/test split on data using sklearn\n",
    "    * Find useful filtering categories for linear regression based on trial and error\n",
    "    * Try getting as accurate as possible given less-refined approach\n",
    "* Model effectiveness measured by average percent error of predictions over test set.\n",
    "    * Values are not great (most successful pass was still around 18% incorrect), but its likely that better accuracy will come with a more refined method\n",
    "* *NOTE: I am not used to using Jupyter notebooks yet. I just wanted to try it out this week as Dr. Iyoob mentioned that we will be submitting with this in the future. I coded everything in Python. I am also not familiar with many data science techniques outside of linear regression and a little bit about neural networks, so this was the best solution I could come up with (as I'm assuming machine learning would be overkill on a dataset this size).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import File\n",
    "I am importing from my current working directory using Pandas' read_csv() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = pd.read_csv(os.getcwd() + r'\\tips.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Tip Percentage into Dataframe\n",
    "Rather than using tip values directly, the regression is going to be based off tip percentage as a function of the total bill paid in order to give a common basis for comparision between sizes of tips. People tend to pay differently depending on how large their bill is, and there is more consistency in the trend for percentage values than tip size (especially at higher bill sizes), even if the values themselves are not as relatively close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = list(map(lambda x, y: x/y, tips['tip'], tips['total_bill']))\n",
    "tips['percent_tip'] = percentage\n",
    "\n",
    "# plots for visualization purposes\n",
    "plt.figure()\n",
    "plt.scatter(train['total_bill'], train['tip'])\n",
    "plt.title(\"Tip Value vs. Total Bill\")\n",
    "plt.xlabel(\"Total Bill ($)\")\n",
    "plt.ylabel(\"Tip ($)\")\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(train['total_bill'], train['percent_tip'])\n",
    "plt.title(\"Percent Tip vs. Total Bill\")\n",
    "plt.xlabel(\"Total Bill ($)\")\n",
    "plt.ylabel(\"Percent Tip (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Outliers\n",
    "Any outliers which are over 2.5 standard deviations from the mean are removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(tips['percent_tip']))\n",
    "tips = tips.drop(np.where(z>2.5)[0], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform 80/20 Train/Test Split\n",
    "The train dataframe will serve as the source for the data I will fit predictions on. The test data will be the points that I am trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(tips, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "I manually changed the categories that were being filtered out based on the input test point in order to see what combinations would be the most accurate. Through trial and error, I found that the most effective combination of filters came when pairing gender with time of day. The loop below goes through the entire test set and yields an average percent error value that served as the basis of my evaluation of the model. I also print a percentage of predictions that are within 5% of the actual tip value as a measure of the number of predictions that were \"incredibly\" accurate relative to the test data as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_error = 0\n",
    "acc_pred = 0\n",
    "\n",
    "for i in test.index:\n",
    "    \n",
    "    # total_bill and tip_real are going to be used to calculate the predicted tip and measure accuracy of the model\n",
    "    total_bill = test['total_bill'][i]\n",
    "    tip_real = test['tip'][i]\n",
    "    \n",
    "    # placing attributes to be used as filters in separate directory\n",
    "    attributes = {\n",
    "        'sex': test['sex'][i], \n",
    "        'smoker': test['smoker'][i], \n",
    "        'day': test['day'][i], \n",
    "        'time': test['time'][i], \n",
    "        'size': test['size'][i]\n",
    "    }\n",
    "    \n",
    "    # applying filters based on attribute dictionary and creating subset of train data to perform regression on\n",
    "    subset = train\n",
    "    subset_temp = pd.DataFrame()\n",
    "    for key in attributes:\n",
    "        if key in ['sex','time']:\n",
    "            subset_temp = subset[(subset[key] == attributes[key])]\n",
    "        if not subset_temp.empty:\n",
    "            subset = subset_temp\n",
    "            \n",
    "    # performance of linear regression using np.polyfit() and np.polyval()\n",
    "    x, y = subset['total_bill'], subset['percent_tip']\n",
    "    coeffs = np.polyfit(x,y,1)\n",
    "    percentage_pred = np.polyval(coeffs, total_bill)\n",
    "    \n",
    "    # calculating predicted tip from predicted percentage\n",
    "    tip_pred = percentage_pred*total_bill\n",
    "    \n",
    "    # collecting data on error for specific pass\n",
    "    percent_error = abs((tip_real-tip_pred)/tip_real)\n",
    "    print(i, '| Percent Error:', percent_error, '| Real Tip:', tip_real, '| Predicted Tip:', tip_pred)\n",
    "    \n",
    "    # adding data on error for full test set\n",
    "    total_error += percent_error\n",
    "    if percent_error < 0.05:\n",
    "        acc_pred += 1\n",
    "    \n",
    "# print average error over entire test set\n",
    "print('\\nAverage Error:', total_error/len(test))\n",
    "\n",
    "# print percentage of \"incredibly\" accurate predictions (within 5%)\n",
    "print('Accurate Prediction Rate:', acc_pred/len(test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
